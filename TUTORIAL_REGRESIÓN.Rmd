---
title: "Tutorial básico de Regresión"
author: 
- "Lucia Fatima Carbajal Falcon"
- "Arlette Alashka Carmen Tullume"
- "Gabriel Omar Evaristo Jacinto"
date: "2026-01-26"
output: html_document
---

^1^ Universidad Nacional Agraria La Molina; ^2^ Departamento Estadística e Informática

## Introducción

a.  Importancia de la regresión lineal múltiple:

    La regresión lineal múltiple es fundamental porque permite modelar fenómenos complejos donde una variable de interés depende de varios factores a la vez. A diferencia de la regresión simple, esta técnica ofrece una visión más realista al analizar cómo múltiples variables independientes influyen simultáneamente en un resultado, permitiendo aislar el efecto individual de cada una mientras se mantienen las demás constantes.

    Su relevancia radica en su doble capacidad: **explicativa y predictiva**. Por un lado, ayuda a identificar qué factores tienen un impacto real y significativo en un problema; por otro, permite construir fórmulas precisas para predecir escenarios futuros, lo que la convierte en una herramienta indispensable para la toma de decisiones basada en datos en cualquier disciplina científica.

b.  Objetivos de aprendizaje

    \- Objetivo General:

    -   Capacitar al estudiante en la implementación y validación de un modelo de regresión lineal múltiple utilizando el software estadÍstico R.

    \- Objetivos Específicos:

    -   Comprender la importancia de incluir múltiples variables predictoras para explicar un fenómeno real.

    -   Ejecutar los ajustes de modelos lineales mediante la función lm() de R.

    -   Interpretar los coeficientes de regresión y su impacto en la variable respuesta.

    -   Evaluar la calidad del ajuste mediante el coeficiente de determinación R-cuadrado.

    -   Validar los supuestos de normalidad, homecedasticidad e independencia a través de pruebas diagnósticas.

    -   Predecir nuevos valores de la variable respuesta utilizando el modelo final optimizado.

## Caso (dataset)

En la actualidad educativa, el uso de recursos de inteligencia artificial se ha popularizado entre los alumnos como un medio complementario para el aprendizaje y la ejecución de tareas académicas. Sin embargo, hay dudas respecto al verdadero efecto de estas tecnologías en el desempeño académico. Así, el objetivo de este tutorial es examinar cómo el uso de la inteligencia artificial se relaciona con el desempeño académico de los estudiantes, el cual se medirá a través de sus calificaciones posteriores, teniendo en cuenta además aspectos importantes como las horas dedicadas al estudio cada día y el rendimiento académico previo, utilizando un modelo de regresión lineal múltiple.

b.  Origen del dataset: https://www.kaggle.com/datasets/aminasalamt/students-ai-usage-and-academic-performance

## Definición de variables

#### Variable dependiente

1. **nota_despues**\
- **Tipo:** Cuantitativa continua\
- **Descripción:** Calificación final del estudiante tras el periodo de uso de herramientas de IA. Es la variable que deseamos predecir o explicar.

#### Variables independientes

1. **horas_estudio**\
- **Tipo:** Cuantitativa continua\
- **Descripción:** Tiempo promedio diario (en horas) dedicado al estudio personal.

2. **usa_ia**\
- **Tipo:** Cualitativa dicotómica (dummy)\
- **Descripción:** Variable que indica si el estudiante utiliza herramientas de inteligencia artificial como apoyo en sus estudios (1 = sí, 0 = no).

3. **nota_antes**\
- **Tipo:** Cuantitativa continua\
- **Descripción:** Calificación obtenida por el estudiante antes del uso de herramientas de inteligencia artificial.

## Exploración de datos
```{r setup, include=FALSE}
# Cargar librerías
library(dplyr)
```

##### Impotación de datos

```{r}
# Lecutra del dataset
datos = read.csv("students_ai_usage.csv")

# Renombrar columnas para un mejor manejo
datos <- datos |>
  rename(
    edad = age,
    nivel_educativo = education_level,
    horas_estudio = study_hours_per_day,
    usa_ia = uses_ai,
    herramientas_ia = ai_tools_used,
    proposito_ia = purpose_of_ai,
    nota_antes = grades_before_ai,
    nota_despues = grades_after_ai,
    tiempo_pantalla = daily_screen_time_hours
  )

# Convertimos a factor "usa_ia" para que R entienda que "Sí" y "No" son categorías, no solo texto
datos$usa_ia <- factor(datos$usa_ia, levels = c("No", "Yes"), labels = c("No", "Sí"))

# Verificamos los nuevos nombres
head(datos)
```

##### Resumen descriptivo univariado

El análisis univariado es el primer paso esencial para entender la distribución, tendencia central y dispersión de cada variable por separado. Nos permite identificar valores atípicos (outliers), errores de digitación o desequilibrios en las categorías (por ejemplo, si hay muy pocos estudiantes que "No" usan IA), lo cual podría afectar la validez del modelo de regresión posterior.

```{r}
summary(datos$nota_despues)
sd(datos$nota_despues)
hist(datos$nota_despues,
     col = "skyblue",
     main = "Distribución de la nota después",
       xlab = "Nota final")
```

- Variable dependiente: nota_despues

La calificación final de los estudiantes presenta:

- Media: 68.7

- Mediana: 69

- Mínimo – Máximo: 55 a 89

- Desviación estándar: 8.14

Esto indica que las notas finales se concentran alrededor de 69 puntos, con una dispersión moderada. Ademas permite ver cómo se distribuyen las calificaciones finales, si están concentradas en un rango específico y si la forma es aproximadamente simétrica.

```{r}
summary(datos$horas_estudio)
sd(datos$horas_estudio)
hist(datos$horas_estudio,
     col = "lightgreen",
     main = "Distribución de horas de estudio por día",
     xlab = "Horas de estudio")
```

- Variable independiente: horas_estudio

Las horas de estudio diarias muestran:

- Media: 2.99 horas

- Mediana: 2.8 horas

- Rango: 1 a 5 horas

- Desviación estándar: 1.15

Los estudiantes estudian en promedio aproximadamente 3 horas al día. La dispersión es baja a moderada, lo que indica que la mayoría de estudiantes se concentra en un rango similar de tiempo de estudio, sin diferencias excesivas entre ellos.

```{r}
summary(datos$nota_antes)
sd(datos$nota_antes)
hist(datos$nota_antes,
     col = "salmon",
     main = "Distribución de la nota antes",
     xlab = "Nota previa")
```
- Variable independiente: nota_antes

El rendimiento previo presenta:

- Media: 64.77

- Mediana: 63

- Rango: 55 a 75

- Desviación estándar: 6.17

Las calificaciones antes del uso de IA son ligeramente menores que las finales, lo que podría anticipar una mejora general en el desempeño. La variabilidad es moderada, lo que permite que esta variable aporte información relevante al modelo.

```{r}
table(datos$usa_ia)
prop.table(table(datos$usa_ia))
barplot(table(datos$usa_ia),
        col = c("gray70", "steelblue"),
        main = "Uso de herramientas de IA",
        ylab = "Frecuencia")
```

- Variable independiente categórica: usa_ia

La distribución del uso de inteligencia artificial es:

- No usa IA: 60 estudiantes (60%)

- Sí usa IA: 40 estudiantes (40%)

Las proporciones son relativamente equilibradas, lo cual es adecuado para el análisis, ya que ambos grupos tienen tamaños suficientes para comparar sus efectos en el modelo sin generar inestabilidad estadística.

##### Resumen descriptivo bivariado

Se realiza para explorar preliminarmente la relación entre la variable respuesta ($Y$) y cada predictor ($X$). En regresión lineal, buscamos identificar visualmente si existe una tendencia lineal, la fuerza de la asociación y si la variable cualitativa (uses_ai) desplaza de manera evidente el promedio de las calificaciones. Esto justifica la inclusión de estas variables en el modelo final.

1)  Horas de estudio vs Nota después

```{r}
plot(datos$horas_estudio, datos$nota_despues,
     col = "darkgreen",
     pch = 16,
     xlab = "Horas de estudio por día",
     ylab = "Nota después",
     main = "Relación entre horas de estudio y nota final")

abline(lm(nota_despues ~ horas_estudio, data = datos), col = "red", lwd = 2)
cor(datos$horas_estudio, datos$nota_despues)
```

El diagrama de dispersión muestra la relación entre las horas de estudio diarias y la calificación final obtenida por los estudiantes. Visualmente, los puntos aparecen bastante dispersos y no se observa una tendencia lineal fuerte. La línea de regresión (en rojo) tiene una pendiente levemente positiva, pero muy pequeña. El coeficiente de correlación calculado es 0.075 el cual valor es muy cercano a 0, lo que indica una relación lineal positiva extremadamente débil entre las horas de estudio y la nota final. En términos prácticos, esto sugiere que, en este conjunto de datos, aumentar las horas de estudio no está fuertemente asociado con un incremento notable en la calificación después del uso de IA.

2)  Nota antes vs Nota después

```{r}
plot(datos$nota_antes, datos$nota_despues,
     col = "purple",
     pch = 16,
     xlab = "Nota antes",
     ylab = "Nota después",
     main = "Relación entre nota previa y nota final")

abline(lm(nota_despues ~ nota_antes, data = datos), col = "red", lwd = 2)
cor(datos$nota_antes, datos$nota_despues)
```

El diagrama de dispersión muestra una tendencia lineal positiva bien definida entre la calificación previa del estudiante y su calificación final. A medida que aumenta la nota antes, también aumenta la nota después. La línea de regresión (en rojo) refleja claramente esta pendiente ascendente. El coeficiente de correlación obtenido es 0.756 el cual indica una correlación lineal positiva fuerte. En términos prácticos, significa que los estudiantes que ya tenían un buen rendimiento académico tienden a mantener ese buen desempeño posteriormente.

3)  Uso de IA vs Nota despues

```{r}
boxplot(nota_despues ~ usa_ia, data = datos,
        col = c("gray80", "skyblue"),
        xlab = "Uso de IA",
        ylab = "Nota después",
        main = "Nota final según uso de IA")

tapply(datos$nota_despues, datos$usa_ia, mean)

```

El diagrama de cajas permite comparar la distribución de las calificaciones finales entre los estudiantes que usan IA y los que no la usan.

**Se observa que:**

- La mediana de las notas finales es claramente mayor en el grupo que sí usa IA.

- La mayor parte de las calificaciones del grupo “Sí” se concentra en valores más altos que las del grupo “No”.

Aunque existe cierta variabilidad en ambos grupos, la distribución completa del grupo que usa IA está desplazada hacia arriba.

Esto indica que, de manera descriptiva, los estudiantes que utilizan herramientas de inteligencia artificial tienden a obtener mejores calificaciones finales en comparación con aquellos que no las utilizan.

- Resumen: En conjunto, el análisis exploratorio bivariado respalda la inclusión de las variables horas de estudio, uso de IA y nota previa en el modelo de regresión lineal múltiple, al evidenciar distintos patrones de asociación con la calificación final.

## Modelamiento

#### Formulación del modelo

$$
Y_i = \beta_0 + \beta_1 X_{1} + \beta_2 X_{2} + \beta_3 X_{3} + \varepsilon
$$ 

Dónde:

- $Y:$ nota despues (Calificación final del estudiante)

- $X_1:$ horas estudio (Horas de estudio diarias)

- $X_2:$ usa ia (Variable dummy: 1 si usa IA, 0 si no usa)

- $X_3:$ nota antes (Calificación previa del estudiante)

- $\beta_0:$ intercepto del modelo

- $\beta_1, \beta_2, \beta_3:$ coeficientes de regresión para cada variable explicativa

- $\epsilon:$ error del modelo

#### Ajuste del modelo

```{r}
modelo = lm(nota_despues ~ horas_estudio + usa_ia + nota_antes, data = datos)
modelo |> coef()
```

#### Interpretación de los coeficientes de regresión

$$\hat{Y}= 3.737 + 0.152X_1 + 9.925X_2 + 0.935X_3$$

- 3.737: Es el valor esperado de la nota_despues cuando las horas de estudio, el uso de IA y la nota anterior son cero. En este contexto académico, funciona principalmente como un ajuste matemático del modelo.

- 0.152: Por cada hora adicional de estudio diario, la nota final aumenta en 0.15 puntos.

- 9.925: Los estudiantes que sí usan IA obtienen, en promedio, 9.92 puntos más en su calificación final que aquellos que no la usan, manteniendo constantes las horas de estudio y su nota previa.

- 0.935: Por cada punto adicional que el estudiante tenía en su calificación previa, su nota final aumenta en 0.93 puntos

#### Coeficiente de determinación y coeficiente de determinación ajustado

El coeficiente de determinación $R^2$ mide qué proporción de la variabilidad de la variable dependiente (nota_despues) es explicada por el conjunto de variables independientes incluidas en el modelo: horas de estudio, uso de IA y nota previa.

```{r}
summary(modelo)$r.squared
```

Esto indica que aproximadamente el 92.8% de la variación en las calificaciones finales de los estudiantes puede ser explicada por las variables del modelo. Este es un valor muy alto, lo que sugiere que el modelo tiene un gran poder explicativo.

```{r}
summary(modelo)$adj.r.squared
```

El coeficiente de determinación ajustado fue: $R^2_{ajustado}$ = 92.5% Este valor es muy cercano al $R^2$, lo que indica que las variables incluidas son relevantes y que el modelo no está sobreajustado. Es decir, cada variable aporta información útil para explicar el rendimiento académico final.

#### Verificación del supuesto de normalidad de errores

```{r setup2, include=FALSE}
library(broom)
library(ggplot2)
library(moments)
```

```{r}
# Guardamos los residuales en un objeto
res <- residuals(modelo)

# Gráfico de Normalidad sugerido
data.frame(res) |>
  ggplot(aes(x = res)) +
  geom_histogram(aes(y = ..density..),
                 bins = round(1 + 3.3 * log10(nrow(datos))),
                 fill = "dodgerblue2",
                 alpha = 0.6) +
  geom_density(size = 1.2, color = "darkblue") +
  labs(title = "Distribución de Residuales",
       subtitle = "Histograma con curva de densidad",
       x = "Residuales",
       y = "Densidad") +
  theme_minimal()

```
En el análisis gráfico de los residuales, se observa una distribución aproximadamente simétrica. Sin embargo, la curva de densidad muestra una forma leptocúrtica (apuntamiento pronunciado), lo que sugiere que los errores están muy concentrados alrededor de la media. 

```{r}
data.frame(res) |>
ggplot(aes(sample=res))+
stat_qq(size = 2) +
stat_qq_line(distribution = stats::qnorm)+
labs(x = "Cuantil teórico", y = "Residuales")+
theme_minimal()
```
Al observar el gráfico Q-Q, se aprecia que la mayoría de los residuales se alinean con la diagonal teórica, especialmente en el sector central. No obstante, en los extremos se observa unalejamiento de los puntos, lo cual es coherente con la leptocurtosis detectada en el histograma.

- Coeficiente de asimetría 

$H_0: As = 0$

$H_1: As \neq 0$

$\alpha=0.05$

```{r}
res |> agostino.test()
```

Dado que el p-valor (0.4972) es notablemente mayor al nivel de significancia $\alpha = 0.05$, no se rechaza la hipótesis nula ($H_0$). Esto significa que no existe evidencia suficiente para afirmar que los errores son asimétricos. En términos estadísticos, los residuales presentan una simetría aceptable, lo cual es un indicio favorable para el cumplimiento del supuesto de normalidad.

- Curtosis

$H_0: k = 3$

$H_1: k \neq 3$

$\alpha=0.05$

```{r}
res |> anscombe.test()
```
Observamos que el p-valor (0.09991) es mayor que el nivel de significancia. Por lo tanto, no se rechaza la hipótesis nula (los datos son mesocúrticos).

**En conclusión, tras realizar las pruebas de D'Agostino y Anscombe-Glynn, se obtuvieron p-valores de 0.4972 y 0.0999 respectivamente. Dado que ambos son superiores al nivel de significancia $\alpha = 0.05$, no se rechaza la hipótesis nula de simetría ni la de mesocurtosis. Por lo tanto, a pesar de las irregularidades visuales observadas en los gráficos, contamos con evidencia estadística suficiente para asumir el cumplimiento del supuesto de normalidad en los residuales del modelo.**

- Prueba de normalidad

$H_0:$ los errores siguen una distribucion normal

$H_1:$ los errores no siguen una distribucion normal

$\alpha=0.05$

```{r}
res |> shapiro.test()
```
Al realizar la prueba de Shapiro-Wilk, se obtuvo un p-valor de $7.057 \times 10^{-7}$. Al ser menor al nivel de significancia $\alpha = 0.05$, se rechaza la hipótesis nula, concluyendo que los residuales no siguen una distribución normal. Esta falta de normalidad, impulsada por la marcada leptocurtosis observada en el histograma, sugiere que las inferencias del modelo deben tomarse con cautela.


**TOMAR EN CUENTA**

-   Aunque las pruebas de *asimetría y curtosis* no rechazan la hipótesis de normalidad, la *prueba de Shapiro-Wilk* resulta muy sensible al tamaño muestral, detectando desviaciones de la normalidad. Dado que el tamaño de muestra es moderado, esta discrepancia es esperable. En consecuencia, el supuesto de normalidad se PODRÍA cumplir de manera [*aproximada*]{.underline}, permitiendo continuar con la inferencia bajo el modelo lineal, aunque con cautela en los extremos de la distribución.


#### Verificación del supuesto de homocedasticidad de errores 

```{r}
modelo |> plot(which=1)
```

En la primera imagen, se observa que a medida que los valores ajustados aumentan (hacia la derecha en el eje X), la dispersión de los puntos se vuelve mucho mayor. Los puntos no forman una "banda horizontal" uniforme, sino que parecen abrirse en forma de embudo o abanico.

```{r}
modelo |> plot(which=3)
```

En la segunda imagen, la línea roja tiene una tendencia ascendente marcada. Esto confirma que la magnitud de los residuos (la variabilidad) está creciendo junto con los valores predichos.

Ambos gráficos sugieren la presencia de heterocedasticidad (varianza no constante). Esto indica que el modelo es más preciso para predecir notas bajas que para predecir notas altas.

```{r}
# Usamos augment() para obtener los valores ajustados (.fitted) y los residuales (.resid)
modelo |> 
  augment() |> 
  ggplot(aes(x = .fitted, y = .resid)) +
  geom_point(size = 3, color = "steelblue", alpha = 0.7) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Valores ajustados (Puntaje de diagnóstico)",
       y = "Residual",
       title = "Evaluación de homocedasticidad",
       subtitle = "Modelo: Desempeño académico con IA") +
  theme_minimal()
```

Existe heterocedasticidad. Visualmente, el gráfico tiene forma de "abanico" o "embudo". Esto nos dice que, aunque el modelo capta la tendencia general, hay factores adicionales que afectan a los alumnos destacados que no estamos logrando explicar solo con las horas de estudio o el uso de IA.

```{r}
# Usamos el modelo y la variable 'horas_estudio'
modelo |> augment() |>
  ggplot(aes(x = horas_estudio, y = .resid)) +
  geom_point(size = 3, color = "darkorange", alpha = 0.7) +
  geom_hline(yintercept = 0, color = "black", linetype = "solid") +
  labs(x = "Horas de estudio",
       y = "Residual",
       title = "Evaluación de homocedasticidad por variable",
       subtitle = "Relación: Horas de estudio vs Residuales") +
  theme_minimal()
```

Aunque el modelo identifica una tendencia, la heterocedasticidad detectada en la variable 'horas de estudio' sugiere que el impacto del estudio en la nota final es muy variable entre los alumnos destacados. Esto indica que nuestro modelo es útil, pero sus predicciones deben tomarse con cautela en el rango de alto rendimiento académico.

$H_0$: La varianza de los errores son constantes

$H_1$: La varianza de los errores no son constantes

$\alpha = 0.05$

```{r setup3, include=FALSE}
library(car)
```

```{r}
modelo |> ncvTest()
```

Se rechaza la hipotesis nula, por lo tanto no se verifica el supuesto de homogeneidad de varianza de los errores

#### Verificación del supuesto de independencia de errores 

```{r}
# Usamos los residuales de tu modelo (res) y el total de datos
data.frame(res) |>
  ggplot(aes(x = 1:nrow(datos), y = res)) +
  geom_point(size = 1.5, color = "darkgreen") +
  geom_line(alpha = 0.3) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(x = "Orden de observación", 
       y = "Residual", 
       title = "Evaluación de independencia",
       subtitle = "Gráfico de secuencia de residuos") +
  theme_minimal()
```

El gráfico de secuencia de residuos no muestra patrones sistemáticos, lo que indica que las observaciones son independientes entre sí.

```{r setup4, include=FALSE}
library(ggfortify)
library(TSA)
```

```{r}
# Usamos los residuales de tu modelo
res |> 
  TSA::acf(lag = 18, plot = F) |> 
  autoplot() + 
  labs(x = "Desfase (Lag)", 
       y = "Autocorrelación", 
       title = "Evaluación de independencia (ACF)",
       subtitle = "Gráfico de Autocorrelación de los Residuales") + 
  theme_minimal()
```

Todas las autocorrelaciones son estadísticamente iguales a cero (están dentro de los límites azules de confianza), lo que evidenciaría el cumplimiento del supuesto de independencia de errores.

$H_0$: Los errores son independientes

$H_1$: Los errores no son independientes

$\alpha = 0.05$

```{r}
library(car)
modelo |> 
  durbinWatsonTest(alternative = "two.sided",
                   max.lag = 10,
                   reps = 1e5)
```


Si bien los p-valores de la prueba de Durbin-Watson para todos los retardos son superiores a 0.05, lo que técnicamente valida la independencia, se recomienda observar con cautela el comportamiento de los residuales cada 8 observaciones. Se ha detectado una ligera autocorrelación en el desfase (lag) 8 que, aunque no llega a invalidar el modelo, sugiere la existencia de un patrón menor en la recolección de datos. Fuera de esta observación puntual, no existe evidencia de falta de independencia en el resto de la estructura del modelo.

#### Transformación de datos

En la evaluación de los supuestos del modelo se identificó la presencia de heterocedasticidad en los errores. Una alternativa habitual para abordar este problema consiste en aplicar transformaciones a la variable respuesta, como la transformación logarítmica o Box-Cox, con el objetivo de estabilizar la varianza.

![](https://miro.medium.com/v2/resize:fit:1400/1*7JIZgIWioZxXYiOqJVujXA.png)

No obstante, dado que la variable dependiente corresponde a calificaciones académicas medidas en una escala acotada y de interpretación directa, se decidió mantener el modelo en su forma original. En consecuencia, los resultados inferenciales se presentan con una nota de precaución, reconociendo la presencia de heterocedasticidad.

[*Este modelo se presenta únicamente con fines ilustrativos.*]{.underline}

Con el objetivo de evaluar una posible solución a la heterocedasticidad detectada, se estimó un modelo alternativo aplicando una transformación logarítmica a la variable dependiente.

```{r}
modelo_log <- lm(log(nota_despues) ~ horas_estudio + usa_ia + nota_antes, data = datos)
summary(modelo_log)
```

Los resultados muestran un alto poder explicativo ($R^2 = 0.931$) y coeficientes estadísticamente significativos para el uso de IA y la nota previa. Sin embargo, la interpretación de los coeficientes se realiza en términos porcentuales, lo cual dificulta su lectura en el contexto de calificaciones académicas.

Por esta razón, este modelo se presenta únicamente con fines educativos, manteniéndose como modelo principal el estimado sobre la escala original de las calificaciones, acompañado de una nota de precaución respecto a la heterocedasticidad.


#### Prueba de hipótesis global del modelo

Se evalúa la significancia global del modelo de regresión lineal múltiple mediante el estadístico F, con el objetivo de determinar si el conjunto de variables explicativas aporta información relevante para explicar la calificación posterior al uso de IA.

Las hipótesis planteadas son:

$$
H_0:\ \beta_1 = \beta_2 = \beta_3 = 0
$$

$$
H_1:\ \text{Al menos uno de los coeficientes } \beta_j \neq 0
$$

Prueba global del modelo (estadístico F): 

```{r}

summary(modelo)
anova(modelo)

```

Dado que el p-valor asociado al estadístico F es menor al nivel de significancia $\alpha = 0.05$, se rechaza la hipótesis nula. Por lo tanto, el modelo es globalmente significativo y las variables explicativas contribuyen conjuntamente a explicar la variabilidad de la calificación posterior al uso de IA.

**Nota de precaución:** Esta conclusión se realiza bajo el supuesto de cumplimiento de los supuestos clásicos del modelo de regresión lineal. En presencia de posibles desviaciones, los resultados deben interpretarse con cautela.

